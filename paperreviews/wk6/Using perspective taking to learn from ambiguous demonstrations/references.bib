@article{chernova2010confidence,
abstract = {Learning from demonstration algorithms enable a robot to learn a new policy based on demonstrations provided by a teacher. In this article, we explore a novel research direction, multi-robot learning from demonstration, which extends demonstration based learning methods to collaborative multi-robot domains. Specifically, we study the problem of enabling a single person to teach individual policies to multiple robots at the same time. We present flexMLfD, a task and platform independent multi-robot demonstration learning framework that supports both independent and collaborative multi-robot behaviors. Building upon this framework, we contribute three approaches to teaching collaborative multi-robot behaviors based on different information sharing strategies, and evaluate these approaches by teaching two Sony QRIO humanoid robots to perform three collaborative ball sorting tasks. We then present scalability analysis of flexMLfD using up to seven Sony AIBO robots. We conclude the article by proposing a formalization for a broader multi-robot learning from demonstration research area.},
author = {Chernova, Sonia and Veloso, Manuela},
journal = {International Journal of Social Robotics},
number = {2},
pages = {195--215},
publisher = {Springer},
title = {{Confidence-based multi-robot learning from demonstration}},
volume = {2},
year = {2010}
}
@article{breazeal2006using,
abstract = {This paper addresses an important issue in learning from demonstrations that are provided by “na\"{\i}ve” human teachers—people who do not have expertise in the machine learning algorithms used by the robot. We therefore entertain the possibility that, whereas the average human user may provide sensible demonstrations from a human’s perspective, these same demonstrations may be insufficient, incomplete, ambiguous, or otherwise “flawed” from the perspective of the training set needed by the learning algorithm to generalize properly. To address this issue, we present a system where the robot is modeled as a socially engaged and socially cognitive learner. We illustrate the merits of this approach through an example where the robot is able to correctly learn from “flawed” demonstrations by taking the visual perspective of the human instructor to clarify potential ambiguities.},
author = {Breazeal, Cynthia and Berlin, Matt and Brooks, Andrew and Gray, Jesse and Thomaz, Andrea L},
journal = {Robotics and Autonomous Systems},
number = {5},
pages = {385--393},
publisher = {Elsevier},
title = {{Using perspective taking to learn from ambiguous demonstrations}},
volume = {54},
year = {2006}
}
